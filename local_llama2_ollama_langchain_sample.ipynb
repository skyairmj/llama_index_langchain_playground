{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.autoinfra.cn/docs/integrations/llms/ollama\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/question_answering/local_retrieval_qa\n",
    "\n",
    "Tags: langchain, Ollama, Llama2, RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a well-known entrepreneur, computer scientist, and writer who has made significant contributions to the fields of artificial intelligence, computer science, and startup culture. He is best known as the co-founder of Y Combinator, a successful start-up accelerator that has launched many successful companies, including Airbnb, Dropbox, and Reddit.\n",
      "\n",
      "Graham was born in 1964 in Boston, Massachusetts, and grew up in a family of computer scientists. He received his Bachelor's degree in Computer Science from Harvard University in 1982 and his PhD in Computer Science from the University of California, Berkeley in 1987. After completing his PhD, Graham worked as a researcher at various universities and companies, including the University of California, Los Angeles (UCLA) and Bell Labs.\n",
      "\n",
      "In 1989, Graham co-founded Y Combinator with his wife, Wendy Haisler. Y Combinator is a start-up accelerator that provides funding, mentorship, and resources to early-stage start-ups in exchange for equity. The company has become one of the most successful start-up accelerators in the world, with a portfolio of over 1,900 companies, including many unicorns like Airbnb, Dropbox, and Reddit.\n",
      "\n",
      "Graham is also known for his writing on start-ups, entrepreneurship, and innovation. He has written several influential essays and articles on these topics, including \"How to Make Wealth,\" \"The Idea Machine,\" and \"Why You Should Learn to Program.\" His writing often emphasizes the importance of creating value through innovation and hard work, rather than relying solely on technology or luck.\n",
      "\n",
      "In addition to his work at Y Combinator, Graham has also taught computer science at several universities, including Stanford University and Harvard University. He is a fellow of the Association for Computing Machinery (ACM) and a member of the National Academy of Engineering (NAE).\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2:7b-chat-q8_0\", request_timeout=60.0)\n",
    "\n",
    "resp = llm.complete(\"Who is Paul Graham?\")\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjin/Projects/artificical_intelligence/llm/llm_playground/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Artificial intelligence (AI) has a rich and varied history that spans several decades. Here is a brief overview of some of the key milestones in the development of AI:\n",
      "\n",
      "1. 1950s-1960s: The Dartmouth Conference and the Birth of AI\n",
      "The field of AI was formally established in 1956 at a conference held at Dartmouth College in Hanover, New Hampshire. Attendees included computer scientists, mathematicians, and cognitive scientists who were interested in exploring the possibilities of creating machines that could simulate human intelligence.\n",
      "2. 1951: The Turing Test\n",
      "British mathematician Alan Turing proposed a test to measure a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. The Turing Test has since become a benchmark for measuring the success of AI systems.\n",
      "3. 1956: The First AI Program\n",
      "John McCarthy, a computer scientist at Stanford University, created the first AI program, called the Logical Theorist, which was designed to reason and solve problems using logical deduction.\n",
      "4. 1960s: Rule-Based Expert Systems\n",
      "The development of rule-based expert systems, which used a set of rules to reason and make decisions, marked a significant milestone in the history of AI. These systems were widely used in industries such as banking, healthcare, and manufacturing.\n",
      "5. 1970s: Machine Learning and Neural Networks\n",
      "Machine learning, which enables machines to learn from data without being explicitly programmed, emerged as a key area of research in AI. The development of neural networks, which are modeled after the structure and function of the human brain, also began during this period.\n",
      "6. 1980s: Expert Systems and the AI Winter\n",
      "Expert systems, which were widely marketed as a solution to complex problems, reached their peak in the mid-1980s. However, the field experienced a decline in funding and interest, which became known as the \"AI winter.\"\n",
      "7. 1990s: AI Resurgence and the Rise of Deep Learning\n",
      "The 1990s saw a resurgence of interest in AI, driven by advances in computing power and the availability of large datasets. The development of deep learning algorithms, which are capable of learning and improving on their own, marked a significant breakthrough in the field.\n",
      "8. 2000s: AI Applications and Ethical Concerns\n",
      "The 21st century has seen widespread adoption of AI in various industries, including healthcare, finance, and transportation. However, concerns about the ethical implications of AI, such as bias, privacy, and job displacement, have also grown in tandem with its increasing use.\n",
      "9. 2010s: AI Breakthroughs and the Rise of Big Data\n",
      "The 2010s saw a series of breakthroughs in AI, including the development of deep learning algorithms that can learn from vast amounts of data. This has led to significant advances in areas such as image and speech recognition, natural language processing, and autonomous vehicles.\n",
      "\n",
      "Overall, the history of AI reflects a continuous cycle of innovation, setbacks, and renewed interest in the field. As AI continues to evolve and expand into new areas, it is likely that its impact on society will only continue to grow."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n Artificial intelligence (AI) has a rich and varied history that spans several decades. Here is a brief overview of some of the key milestones in the development of AI:\\n\\n1. 1950s-1960s: The Dartmouth Conference and the Birth of AI\\nThe field of AI was formally established in 1956 at a conference held at Dartmouth College in Hanover, New Hampshire. Attendees included computer scientists, mathematicians, and cognitive scientists who were interested in exploring the possibilities of creating machines that could simulate human intelligence.\\n2. 1951: The Turing Test\\nBritish mathematician Alan Turing proposed a test to measure a machine\\'s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. The Turing Test has since become a benchmark for measuring the success of AI systems.\\n3. 1956: The First AI Program\\nJohn McCarthy, a computer scientist at Stanford University, created the first AI program, called the Logical Theorist, which was designed to reason and solve problems using logical deduction.\\n4. 1960s: Rule-Based Expert Systems\\nThe development of rule-based expert systems, which used a set of rules to reason and make decisions, marked a significant milestone in the history of AI. These systems were widely used in industries such as banking, healthcare, and manufacturing.\\n5. 1970s: Machine Learning and Neural Networks\\nMachine learning, which enables machines to learn from data without being explicitly programmed, emerged as a key area of research in AI. The development of neural networks, which are modeled after the structure and function of the human brain, also began during this period.\\n6. 1980s: Expert Systems and the AI Winter\\nExpert systems, which were widely marketed as a solution to complex problems, reached their peak in the mid-1980s. However, the field experienced a decline in funding and interest, which became known as the \"AI winter.\"\\n7. 1990s: AI Resurgence and the Rise of Deep Learning\\nThe 1990s saw a resurgence of interest in AI, driven by advances in computing power and the availability of large datasets. The development of deep learning algorithms, which are capable of learning and improving on their own, marked a significant breakthrough in the field.\\n8. 2000s: AI Applications and Ethical Concerns\\nThe 21st century has seen widespread adoption of AI in various industries, including healthcare, finance, and transportation. However, concerns about the ethical implications of AI, such as bias, privacy, and job displacement, have also grown in tandem with its increasing use.\\n9. 2010s: AI Breakthroughs and the Rise of Big Data\\nThe 2010s saw a series of breakthroughs in AI, including the development of deep learning algorithms that can learn from vast amounts of data. This has led to significant advances in areas such as image and speech recognition, natural language processing, and autonomous vehicles.\\n\\nOverall, the history of AI reflects a continuous cycle of innovation, setbacks, and renewed interest in the field. As AI continues to evolve and expand into new areas, it is likely that its impact on society will only continue to grow.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler                                  \n",
    "llm = Ollama(base_url=\"http://localhost:11434\", \n",
    "             model=\"llama2:7b-chat-q8_0\", \n",
    "             callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "llm(\"Tell me about the history of AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# 提示\n",
    "template = \"\"\"Use the following context to answer the last question.\n",
    "If you don't know the answer, just say 'I don't know', don't try to make up an answer.\n",
    "Answer the question briefly with maximun three sentences.\n",
    "{context}\n",
    "Question: {question}\n",
    "Useful Answer: \"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "llm = Ollama(base_url=\"http://localhost:11434\",\n",
    "             model=\"llama2:7b-chat-q8_0\",\n",
    "             verbose=True,\n",
    "             callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA链\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjin/Projects/artificical_intelligence/llm/llm_playground/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approaches to AI agent task decomposition include:\n",
      "\n",
      "1. Using large language models (LLM) with simple prompting, such as \"Steps for XYZ.\" or \"What are the subgoals for achieving XYZ?\"\n",
      "2. Using task-specific instructions, such as \"Write a story outline\" for writing a novel.\n",
      "3. Using human inputs to guide the decomposition process."
     ]
    }
   ],
   "source": [
    "question = \"What are the approaches to AI Agent Task Decomposition?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.22003469910937"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62 / (1313002000/1000/1000/1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
